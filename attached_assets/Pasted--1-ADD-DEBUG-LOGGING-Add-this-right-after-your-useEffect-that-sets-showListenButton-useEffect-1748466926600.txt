// 1. ADD DEBUG LOGGING - Add this right after your useEffect that sets showListenButton:

useEffect(() => {
  console.log("ðŸ” LISTEN BUTTON DEBUG:", {
    showListenButton,
    isListening,
    isResponding,
    isVoiceThinking,
    responseComplete,
    hasReceivedFirstResponse,
    usedVoiceInput,
    isProcessing,
    status,
    finalCondition: showListenButton && !isListening && !isResponding
  });
}, [showListenButton, isListening, isResponding, isVoiceThinking, responseComplete, hasReceivedFirstResponse, usedVoiceInput, isProcessing, status]);

// 2. SIMPLIFIED LOGIC - Replace your complex useEffect with this cleaner version:

useEffect(() => {
  console.log("Status check triggered, current status:", status, "isProcessing:", isProcessing);
  if (!isProcessing && status === 'Processing your question...') {
    console.log("âœ… Status condition met - processing complete with correct status");
    
    // Reset the status
    setStatus('');
    
    // Clear thinking state immediately when response is ready
    setIsVoiceThinking(false);
    
    // Always handle voice response if voice input was used
    if (usedVoiceInput) {
      // Mark that we've received the first response
      setHasReceivedFirstResponse(true);
      
      try {
        console.log("Voice input was used - finding message to speak...");
        
        // Find the last assistant message
        const messagesContainer = document.getElementById('conversation');
        console.log("Messages container found:", !!messagesContainer);
        
        if (messagesContainer) {
          const messageElements = messagesContainer.querySelectorAll('[data-role="assistant"]');
          console.log("Assistant message elements found:", messageElements.length);
          
          if (messageElements && messageElements.length > 0) {
            const lastMessage = messageElements[messageElements.length - 1];
            
            if (lastMessage && lastMessage.textContent) {
              const messageText = lastMessage.textContent || '';
              console.log("Found message to speak:", messageText.substring(0, 50) + "...");
              
              // Store the message text
              (window as any).lastResponseText = messageText;
              console.log("ðŸ’¾ Stored response text for Listen Response");
              
              // SIMPLIFIED STATE SETTING - just set these once
              setIsVoiceThinking(false);
              setIsResponding(false);
              setResponseComplete(true);
              setHasReceivedFirstResponse(true);
              setShowListenButton(true);  // This should make it show
              setShowBottomSheet(true);
              
              console.log("âœ… Set showListenButton to TRUE - it should appear now!");
            }
          }
        }
      } catch (error) {
        console.error('Error finding assistant message:', error);
      }
    }
  }
}, [isProcessing, status, usedVoiceInput]);

// 3. CHECK YOUR VoiceBottomSheet COMPONENT - Make sure it handles showListenButton prop:
// In your VoiceBottomSheet component, you should have something like:

{showListenButton && (
  <button onClick={onListenResponse}>
    Listen Response
  </button>
)}

// 4. MANUAL TEST - Add this button temporarily to force show the Listen button:
{/* Add this button temporarily for testing */}
<button 
  onClick={() => {
    console.log("ðŸ§ª Manual test - forcing showListenButton to true");
    setShowListenButton(true);
    setShowBottomSheet(true);
    setIsVoiceThinking(false);
    setIsResponding(false);
    setResponseComplete(true);
  }}
  style={{
    position: 'fixed',
    top: '100px',
    right: '10px',
    background: 'red',
    color: 'white',
    padding: '10px',
    zIndex: 9999
  }}
>
  TEST LISTEN BUTTON
</button>