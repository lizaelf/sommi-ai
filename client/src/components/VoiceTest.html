<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice Assistant Test</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      line-height: 1.6;
    }
    
    h1 {
      color: #6A53E7;
      text-align: center;
    }
    
    .container {
      border: 1px solid #e1e1e1;
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
      background-color: #f9f9f9;
    }
    
    #conversation {
      min-height: 300px;
      margin-bottom: 20px;
    }
    
    .controls {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin-bottom: 20px;
    }
    
    button {
      padding: 10px 15px;
      border: none;
      border-radius: 5px;
      background-color: #6A53E7;
      color: white;
      cursor: pointer;
      transition: background-color 0.2s;
    }
    
    button:hover {
      background-color: #5442c8;
    }
    
    button:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }
    
    #mic-button.listening {
      animation: pulse 1.5s infinite;
      background-color: #ff4136;
    }
    
    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.7; }
      100% { opacity: 1; }
    }
    
    #status {
      text-align: center;
      font-weight: bold;
      min-height: 1.5em;
      color: #6A53E7;
    }
    
    #audio-controls {
      margin-top: 15px;
      text-align: center;
    }
    
    #play-audio-btn {
      padding: 10px 20px;
      background-color: #8B0000;
      color: white;
      border: none;
      border-radius: 5px;
    }
    
    .message {
      margin-bottom: 10px;
      padding: 10px;
      border-radius: 8px;
    }
    
    .user {
      background-color: #f0f0f0;
      margin-left: 20%;
      text-align: right;
    }
    
    .assistant {
      background-color: #e6e6fa;
      margin-right: 20%;
    }
  </style>
</head>
<body>
  <h1>Voice Assistant Test</h1>
  
  <div class="container">
    <div id="conversation">
      <div class="message assistant" data-role="assistant">
        Hi! I'm your personal wine sommelier. How can I help you today?
      </div>
    </div>
    
    <div id="audio-controls" style="display: none;">
      <button id="play-audio-btn">
        Play Response Audio
      </button>
    </div>
    
    <div id="status"></div>
    
    <div class="controls">
      <button id="mic-button">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"></path>
          <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
          <line x1="12" x2="12" y1="19" y2="22"></line>
        </svg>
        Microphone
      </button>
      <button id="test-button">Test Audio</button>
      <button id="add-message">Add Test Message</button>
    </div>
  </div>
  
  <script>
    // Variable to store the last audio blob for playback
    let lastAudioBlob = null;
    let statusDiv = null;
    
    // DOM load event to initialize everything
    document.addEventListener('DOMContentLoaded', function() {
      // Get elements
      const micButton = document.getElementById('mic-button');
      const testButton = document.getElementById('test-button');
      const addMessageButton = document.getElementById('add-message');
      statusDiv = document.getElementById('status');
      
      // Speech recognition setup
      let recognition = null;
      if (window.SpeechRecognition || window.webkitSpeechRecognition) {
        recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = 'en-US';
        recognition.continuous = false;
        recognition.interimResults = false;
        
        recognition.onresult = function(event) {
          const transcript = event.results[0][0].transcript;
          statusDiv.textContent = 'Processing your question...';
          
          // Add user message
          addUserMessage(transcript);
          
          // Simulate AI response after a delay
          setTimeout(() => {
            const response = "This is a simulated response about Cabernet Sauvignon. It's one of the world's most widely recognized red wine grape varieties. It is grown in nearly every major wine producing country among a diverse spectrum of climates from Australia and British Columbia to Lebanon's Beqaa Valley.";
            addAssistantMessage(response);
            speakResponse(response);
          }, 1000);
        };
        
        recognition.onend = function() {
          micButton.classList.remove('listening');
          statusDiv.textContent = '';
        };
        
        recognition.onstart = function() {
          micButton.classList.add('listening');
          statusDiv.textContent = 'Listening for your question...';
        };
        
        recognition.onerror = function(event) {
          console.error('Speech recognition error:', event.error);
          statusDiv.textContent = `Error: ${event.error}`;
          micButton.classList.remove('listening');
        };
      }
      
      // Microphone button click handler
      micButton.addEventListener('click', function() {
        if (!recognition) {
          alert("Your browser doesn't support speech recognition. Try using Chrome.");
          return;
        }
        
        if (micButton.classList.contains('listening')) {
          recognition.stop();
        } else {
          try {
            recognition.start();
          } catch (error) {
            console.error('Failed to start speech recognition:', error);
            alert("Failed to start speech recognition. Please try again.");
          }
        }
      });
      
      // Test button click handler
      testButton.addEventListener('click', function() {
        const testText = "This is a test of the Cabernet Sauvignon wine assistant voice. I hope you can hear me clearly now.";
        speakResponse(testText);
      });
      
      // Add message button click handler
      addMessageButton.addEventListener('click', function() {
        addAssistantMessage("Cabernet Sauvignon is one of the world's most widely recognized red wine grape varieties. It is grown in nearly every major wine producing country among a diverse spectrum of climates from Australia and British Columbia to Lebanon's Beqaa Valley.");
      });
      
      // Set up audio context for better audio support
      try {
        window.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        console.log('Audio context created');
      } catch (e) {
        console.warn('Unable to initialize AudioContext:', e);
      }
    });
    
    // Helper function to add a user message
    function addUserMessage(text) {
      const conversation = document.getElementById('conversation');
      const messageDiv = document.createElement('div');
      messageDiv.className = 'message user';
      messageDiv.textContent = text;
      conversation.appendChild(messageDiv);
      conversation.scrollTop = conversation.scrollHeight;
    }
    
    // Helper function to add an assistant message
    function addAssistantMessage(text) {
      const conversation = document.getElementById('conversation');
      const messageDiv = document.createElement('div');
      messageDiv.className = 'message assistant';
      messageDiv.setAttribute('data-role', 'assistant');
      messageDiv.textContent = text;
      conversation.appendChild(messageDiv);
      conversation.scrollTop = conversation.scrollHeight;
    }
    
    // Function to speak responses
    async function speakResponse(text) {
      try {
        statusDiv.textContent = 'Getting voice response...';
        
        const response = await fetch('/api/text-to-speech', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text })
        });
        
        if (!response.ok) throw new Error(`HTTP error: ${response.status}`);
        
        // Save the audio blob for later use
        lastAudioBlob = await response.blob();
        console.log("Audio received:", lastAudioBlob.size, "bytes");
        
        // Show the audio controls
        const audioControls = document.getElementById('audio-controls');
        audioControls.style.display = 'block';
        
        // Set up the play button
        const playBtn = document.getElementById('play-audio-btn');
        playBtn.onclick = playLastAudio;
        
        statusDiv.textContent = 'Audio ready to play';
      } catch (error) {
        console.error("Error:", error);
        statusDiv.textContent = 'Failed to get audio';
      }
    }
    
    function playLastAudio() {
      if (!lastAudioBlob) {
        console.error("No audio available");
        return;
      }
      
      const url = URL.createObjectURL(lastAudioBlob);
      const audio = new Audio(url);
      
      audio.onended = () => {
        URL.revokeObjectURL(url);
      };
      
      audio.play().catch(err => {
        console.error("Playback error:", err);
      });
      
      statusDiv.textContent = 'Playing...';
    }
  </script>
</body>
</html>