import React, { useEffect, useState, useMemo, useCallback } from "react";
import { useQuery } from "@tanstack/react-query";
import { suggestionCache } from "@/utils/suggestionCache";
import Button from "@/components/ui/Button";
import typography from "@/styles/typography";
import wineResponses from "@/../../shared/wineResponses.json";

interface SuggestionPill {
  id: string;
  text: string;
  prompt: string;
}

interface SuggestionPillsProps {
  wineKey: string;
  conversationId?: string; // Add conversation context
  onSuggestionClick: (
    prompt: string,
    pillId?: string,
    options?: {
      textOnly?: boolean;
      instantResponse?: string;
      conversationId?: string;
    },
  ) => void;
  isDisabled?: boolean;
  preferredResponseType?: "text" | "voice";
  context?: "chat" | "voice-assistant";
}

export default function SuggestionPills({
  wineKey,
  conversationId,
  onSuggestionClick,
  isDisabled = false,
  preferredResponseType = "text",
  context = "chat",
}: SuggestionPillsProps) {
  const [usedPills, setUsedPills] = useState<Set<string>>(new Set());
  const [isProcessing, setIsProcessing] = useState(false);
  const [isResetting, setIsResetting] = useState(false);
  const [currentAbortController, setCurrentAbortController] = useState<AbortController | null>(null);
  const [preGenerationStatus, setPreGenerationStatus] = useState<Map<string, 'loading' | 'ready' | 'failed'>>(new Map());
  const [loadingPillId, setLoadingPillId] = useState<string | null>(null);
  const [audioLoadTimeout, setAudioLoadTimeout] = useState<NodeJS.Timeout | null>(null);

  // Default suggestions to show immediately while API loads
  const defaultSuggestions: SuggestionPill[] = [
    {
      id: "default-1",
      text: "Tell me about this wine",
      prompt: "Tell me about this wine",
    },
    {
      id: "default-2",
      text: "What's the story behind it?",
      prompt: "What's the story behind this wine?",
    },
    {
      id: "default-3",
      text: "Food pairing suggestions",
      prompt: "What food pairs well with this wine?",
    },
  ];

  // Fetch available suggestion pills for this wine
  const effectiveWineKeyForQuery = wineKey || "wine_1";
  const {
    data: suggestionsData,
    isLoading,
    refetch,
  } = useQuery({
    queryKey: ["/api/suggestion-pills", effectiveWineKeyForQuery],
    queryFn: async () => {
      const response = await fetch(
        `/api/suggestion-pills/${encodeURIComponent(effectiveWineKeyForQuery)}`,
      );
      if (!response.ok) {
        throw new Error("Failed to fetch suggestion pills");
      }
      return response.json();
    },
    enabled: true, // Always enabled since we have fallback wine key
    staleTime: 5 * 60 * 1000,
    refetchOnWindowFocus: false,
    refetchOnMount: false,
    refetchOnReconnect: false,
    refetchInterval: false,
  });

  // Manual reset function - only triggered by user interaction
  const resetSuggestionPills = useCallback(() => {
    const effectiveWineKey = wineKey || "wine_1";
    console.log("Manually resetting suggestion cycle for wine:", effectiveWineKey);
    setIsResetting(true);

    fetch(`/api/suggestion-pills/${encodeURIComponent(effectiveWineKey)}/reset`, {
      method: "DELETE",
    })
      .then(() => {
        setUsedPills(new Set());
        setIsResetting(false);
        refetch(); // Refresh suggestions after reset
      })
      .catch((error) => {
        console.error("Failed to reset suggestion pills:", error);
        setIsResetting(false);
      });
  }, [wineKey, refetch]);

  // Removed automatic reset - suggestions only change when user clicks

  // Eager pre-generation for all contexts to improve responsiveness
  useEffect(() => {
    if (context === "voice-assistant") {
      // Pre-generate for API suggestions when available
      if (suggestionsData?.suggestions && !isLoading) {
        preGenerateSuggestionAudio(suggestionsData.suggestions);
      }
      // Always pre-generate for default suggestions
      preGenerateSuggestionAudio(defaultSuggestions);
    }
  }, [context, suggestionsData, isLoading]);

  // Enhanced pre-generation with status tracking and fallbacks
  const preGenerateSuggestionAudio = async (suggestions?: SuggestionPill[]) => {
    const pillsToProcess = suggestions || suggestionsData?.suggestions || defaultSuggestions;
    if (!pillsToProcess?.length) return;

    console.log("üé§ PRE-GEN: Starting enhanced audio pre-generation");
    const audioCache = (window as any).suggestionAudioCache || {};
    (window as any).suggestionAudioCache = audioCache;

    const effectiveWineKey = wineKey || "wine_1";

    for (const pill of pillsToProcess.slice(0, 3)) {
      const suggestionId = pill.prompt.toLowerCase().replace(/[^a-z0-9]+/g, "_");
      const cacheKey = `${effectiveWineKey}_${suggestionId}`;

      // Update pre-generation status
      setPreGenerationStatus(prev => new Map(prev).set(cacheKey, 'loading'));

      if (audioCache[cacheKey]) {
        setPreGenerationStatus(prev => new Map(prev).set(cacheKey, 'ready'));
        console.log(`üé§ PRE-GEN: Audio already cached for "${pill.text}"`);
        continue;
      }

      const wineData = wineResponses[effectiveWineKey as keyof typeof wineResponses];
      if (wineData?.responses) {
        const responseText = wineData.responses[suggestionId as keyof typeof wineData.responses];
        if (responseText) {
          try {
            console.log(`üé§ PRE-GEN: Generating audio for "${pill.text}"`);
            const response = await fetch("/api/text-to-speech", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ text: responseText }),
            });

            if (response.ok) {
              const audioBuffer = await response.arrayBuffer();
              const audioBlob = new Blob([audioBuffer], { type: 'audio/mpeg' });
              const audioUrl = URL.createObjectURL(audioBlob);
              audioCache[cacheKey] = audioUrl;
              setPreGenerationStatus(prev => new Map(prev).set(cacheKey, 'ready'));
              console.log(`üé§ PRE-GEN: ‚úÖ Audio cached for "${pill.text}"`);
            } else {
              setPreGenerationStatus(prev => new Map(prev).set(cacheKey, 'failed'));
              console.error(`üé§ PRE-GEN: TTS request failed for "${pill.text}"`);
            }
          } catch (error) {
            setPreGenerationStatus(prev => new Map(prev).set(cacheKey, 'failed'));
            console.error(`üé§ PRE-GEN: Failed to generate audio for "${pill.text}":`, error);
          }
        } else {
          setPreGenerationStatus(prev => new Map(prev).set(cacheKey, 'failed'));
          console.log(`üé§ PRE-GEN: No spreadsheet response for "${pill.text}", skipping pre-generation`);
        }
      } else {
        setPreGenerationStatus(prev => new Map(prev).set(cacheKey, 'failed'));
        console.log(`üé§ PRE-GEN: No wine data found for "${effectiveWineKey}"`);
      }
    }
  };

  // Listen for abort conversation events (when user closes voice assistant)
  useEffect(() => {
    const handleAbortConversation = () => {
      console.log("üõë SuggestionPills: Received abort signal - stopping all API requests");

      // Abort current API request if ongoing
      if (currentAbortController) {
        currentAbortController.abort();
        setCurrentAbortController(null);
      }

      // Reset processing state
      setIsProcessing(false);

      // Stop any ongoing audio
      if ((window as any).currentOpenAIAudio) {
        (window as any).currentOpenAIAudio.pause();
        (window as any).currentOpenAIAudio.currentTime = 0;
        (window as any).currentOpenAIAudio = null;
      }
    };

    window.addEventListener('abortConversation', handleAbortConversation);

    return () => {
      window.removeEventListener('abortConversation', handleAbortConversation);
    };
  }, [currentAbortController]);

  const handlePillClick = async (pill: SuggestionPill) => {
    console.log("üîç DEBUGGING: handlePillClick called with context:", context, "preferredResponseType:", preferredResponseType);
    console.log("üîç DEBUGGING: wineKey:", wineKey, "pill:", pill);
    if (isDisabled) return;

    // Optimistically mark as used
    setUsedPills((prev) => {
      const newSet = new Set(prev);
      newSet.add(pill.id);
      return newSet;
    });

    try {
      // Check for instant response (cached or spreadsheet)
      let instantResponse = null;
      const suggestionId = pill.prompt
        .toLowerCase()
        .replace(/[^a-z0-9]+/g, "_");

      // Use effective wine key for cache lookup
      const effectiveWineKey = wineKey || "wine_1"; // Default to wine_1 when wineKey is empty
      console.log("üîç Cache lookup using effectiveWineKey:", effectiveWineKey);

      // First check spreadsheet data for voice suggestions
      if (context === "voice-assistant") {
        console.log("üîç VOICE DEBUG: Looking for wine data with key:", effectiveWineKey);
        console.log("üîç VOICE DEBUG: Available wine keys:", Object.keys(wineResponses));
        const wineData = wineResponses[effectiveWineKey as keyof typeof wineResponses];
        console.log("üîç VOICE DEBUG: Found wine data:", !!wineData);
        if (wineData && wineData.responses) {
          console.log("üîç VOICE DEBUG: Available response keys:", Object.keys(wineData.responses));
          console.log("üîç VOICE DEBUG: Looking for suggestion ID:", suggestionId);
          const spreadsheetResponse = wineData.responses[suggestionId as keyof typeof wineData.responses];
          if (spreadsheetResponse) {
            console.log("üìä Using spreadsheet response for voice suggestion:", suggestionId);
            instantResponse = spreadsheetResponse;
          } else {
            console.log("‚ùå No spreadsheet response found for:", suggestionId);
          }
        }
      }

      // Fallback to cache lookup if no spreadsheet response
      if (!instantResponse) {
        instantResponse = await suggestionCache.getCachedResponse(
          effectiveWineKey,
          suggestionId,
        );
      }
      console.log(
        "üíæ Cached response found:",
        !!instantResponse,
        "Context:",
        context,
        "PillId:",
        pill.id,
        "PreferredType:",
        preferredResponseType
      );

      // CHAT CONTEXT: Handle text-only, no audio
      if (context === "chat") {
        console.log(
          "üí¨ CHAT CONTEXT: Processing suggestion for chat interface",
        );

        if (instantResponse) {
          console.log(
            "üí¨ CHAT: Using cached response - adding to chat WITHOUT audio",
          );

          // Add messages to chat using the event system
          const userMessage = {
            id: Date.now(),
            content: pill.text, // Use pill.text to match what's shown on the button
            role: "user" as const,
            conversationId: conversationId || 0,
            createdAt: new Date().toISOString(),
          };

          const assistantMessage = {
            id: Date.now() + 1,
            content: instantResponse,
            role: "assistant" as const,
            conversationId: conversationId || 0,
            createdAt: new Date().toISOString(),
          };

          // Use chat event system - NO AUDIO
          window.dispatchEvent(
            new CustomEvent("addChatMessage", {
              detail: { userMessage, assistantMessage },
            }),
          );

          console.log("üí¨ CHAT: Messages added to chat - NO AUDIO PLAYED");
        } else {
          console.log("üí¨ CHAT: No cache - using normal API flow");
          // No cached response - let chat handle API call
          // Send the button text to display in chat, but use the full prompt for the API
          onSuggestionClick(pill.text, pill.id, {
            textOnly: true,
            conversationId,
            fullPrompt: pill.prompt, // Include full prompt for API processing
          });
        }

        // Mark as used in background for chat context
        markPillAsUsed(pill.id);
        return; // EXIT EARLY - Chat context handled
      }

      // VOICE CONTEXT: Handle with audio
      if (context === "voice-assistant") {
        console.log(
          "üé§ VOICE CONTEXT: Processing suggestion for voice assistant",
        );

        setIsProcessing(true);

        // Immediately dispatch TTS start event to show stop button
        window.dispatchEvent(new CustomEvent("tts-audio-start"));
        console.log("üé§ VOICE: Dispatched TTS start event for stop button");

        if (instantResponse) {
          const responseSource = instantResponse.length > 200 ? "spreadsheet" : "cache";
          console.log(`üé§ VOICE: Using ${responseSource} response - starting TTS immediately`);

          // Check if we have pre-generated audio for this suggestion
          const audioCache = (window as any).suggestionAudioCache || {};
          const cacheKey = `${effectiveWineKey}_${suggestionId}`;

          if (audioCache[cacheKey]) {
            console.log("üé§ VOICE: Using pre-generated audio for instant playback");
            const audio = new Audio(audioCache[cacheKey]);

            audio.onplay = () => {
              console.log("üé§ VOICE: ‚úÖ Pre-generated audio started");
              window.dispatchEvent(new CustomEvent("tts-audio-start"));
            };

            audio.onended = () => {
              console.log("üé§ VOICE: Pre-generated audio completed");
              setIsProcessing(false);
              window.dispatchEvent(new CustomEvent("tts-audio-stop"));
            };

            audio.onerror = (e) => {
              console.error("üé§ VOICE: Pre-generated audio error:", e);
              setIsProcessing(false);
              window.dispatchEvent(new CustomEvent("tts-audio-stop"));
            };

            (window as any).currentOpenAIAudio = audio;
            await audio.play();

            // Add messages to chat
            const userMessage = {
              id: Date.now(),
              content: pill.prompt,
              role: "user" as const,
              conversationId: conversationId || 0,
              createdAt: new Date().toISOString(),
            };

            const assistantMessage = {
              id: Date.now() + 1,
              content: instantResponse,
              role: "assistant" as const,
              conversationId: conversationId || 0,
              createdAt: new Date().toISOString(),
            };

            window.dispatchEvent(
              new CustomEvent("addChatMessage", {
                detail: { userMessage, assistantMessage },
              }),
            );

            markPillAsUsed(pill.id);
            return;
          }

          // Optimized TTS generation with high priority for immediate response
          console.log("üé§ VOICE: Making high-priority TTS request");
          const response = await fetch("/api/text-to-speech", {
            method: "POST",
            headers: { 
              "Content-Type": "application/json",
              "Cache-Control": "no-cache", // Prevent caching delays
              "Priority": "urgent" // Request priority hint
            },
            body: JSON.stringify({ 
              text: instantResponse.slice(0, 1000), // Limit text length for faster processing
              optimize: "speed" // Server optimization hint
            }),
            signal: currentAbortController?.signal,
          });

          if (response.ok) {
            const audioBuffer = await response.arrayBuffer();
            const audioBlob = new Blob([audioBuffer], { type: 'audio/mpeg' });
            const audioUrl = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioUrl);

            // Optimize for immediate playback
            audio.preload = 'auto';
            audio.crossOrigin = 'anonymous';

            console.log("üé§ VOICE: TTS ready - starting immediate playback");

            audio.onloadeddata = () => {
              console.log("üé§ VOICE: Audio data loaded, starting playback");
              audio.play().catch(console.error);
            };

            audio.onplay = () => {
              console.log("üé§ VOICE: ‚úÖ Audio playback started successfully");
              window.dispatchEvent(new CustomEvent("tts-audio-start"));
            };

            audio.onended = () => {
              console.log("üé§ VOICE: Audio playback completed");
              URL.revokeObjectURL(audioUrl);
              setIsProcessing(false);
              window.dispatchEvent(new CustomEvent("tts-audio-stop"));
            };

            audio.onerror = (e) => {
              console.error("üé§ VOICE: Audio playback error:", e);
              URL.revokeObjectURL(audioUrl);
              setIsProcessing(false);
              window.dispatchEvent(new CustomEvent("tts-audio-stop"));
            };

            (window as any).currentOpenAIAudio = audio;

            // Try immediate playback - audio will start when data loads
            try {
              console.log("üé§ VOICE: Starting immediate audio playback");
              await audio.play();
              console.log("üé§ VOICE: ‚úÖ Audio playback initiated successfully");
            } catch (playError) {
              console.error("üé§ VOICE: Immediate playback failed:", playError);
              // Fallback: wait for loadeddata event
              audio.addEventListener('canplay', () => {
                audio.play().catch(console.error);
              });
              setIsProcessing(false);
            }
          }

          // Add messages to chat in parallel
          const userMessage = {
            id: Date.now(),
            content: pill.prompt,
            role: "user" as const,
            conversationId: conversationId || 0,
            createdAt: new Date().toISOString(),
          };

          const assistantMessage = {
            id: Date.now() + 1,
            content: instantResponse,
            role: "assistant" as const,
            conversationId: conversationId || 0,
            createdAt: new Date().toISOString(),
          };

          // Use chat event system
          window.dispatchEvent(
            new CustomEvent("addChatMessage", {
              detail: { userMessage, assistantMessage },
            }),
          );

          // Mark pill as used and complete processing
          markPillAsUsed(pill.id);
          return; // Exit early - TTS already started above
        } else {
          // No cached response - make API call
          console.log("üé§ VOICE: No cache - making direct API call for voice response");

          const response = await fetch("/api/chat", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              messages: [{ role: "user", content: pill.prompt }],
              wineKey: effectiveWineKey,
              wineData: { id: null, name: "Ridge \"Lytton Springs\" Dry Creek Zinfandel" },
              textOnly: false,
            }),
            signal: currentAbortController?.signal,
          });

          if (!response.ok) {
            throw new Error(`API request failed: ${response.status}`);
          }

          const data = await response.json();
          const responseText = data.message?.content || "";

          if (responseText && data.audioBuffers && data.audioBuffers.length > 0) {
            // Store response in cache for future use
            await suggestionCache.storeResponse(
              effectiveWineKey,
              suggestionId,
              responseText,
            );

            // Add messages to chat
            const userMessage = {
              id: Date.now(),
              content: pill.prompt,
              role: "user" as const,
              conversationId: conversationId || 0,
              createdAt: new Date().toISOString(),
            };

            const assistantMessage = {
              id: Date.now() + 1,
              content: responseText,
              role: "assistant" as const,
              conversationId: conversationId || 0,
              createdAt: new Date().toISOString(),
            };

            window.dispatchEvent(
              new CustomEvent("addChatMessage", {
                detail: { userMessage, assistantMessage },
              }),
            );

            // Play audio from API response
            for (const buffer of data.audioBuffers) {
              const audioBlob = new Blob([buffer], { type: 'audio/mpeg' });
              const audioUrl = URL.createObjectURL(audioBlob);
              const audio = new Audio(audioUrl);

              await new Promise((resolve, reject) => {
                audio.onended = () => {
                  URL.revokeObjectURL(audioUrl);
                  resolve(undefined);
                };
                audio.onerror = reject;
                audio.play();
              });
            }
          }
        }

        // Mark as used in background for voice context
        markPillAsUsed(pill.id);
        return; // EXIT EARLY - Voice context handled
      }

      // Fallback for unknown context
      console.warn("‚ö†Ô∏è Unknown context:", context, "- using default behavior");
      onSuggestionClick(pill.prompt, pill.id, {
        textOnly: context === "chat",
        conversationId,
      });
    } catch (error) {
      // Rollback optimistic update on error
      setUsedPills((prev) => {
        const newSet = new Set(prev);
        newSet.delete(pill.id);
        return newSet;
      });
      console.error("Error handling pill click:", error);
    } finally {
      setIsProcessing(false);
      setCurrentAbortController(null);
      setLoadingPillId(null);
      // Clear any pending timeout
      if (audioLoadTimeout) {
        clearTimeout(audioLoadTimeout);
        setAudioLoadTimeout(null);
      }
    }
  };

  // Helper function to mark pill as used
  const markPillAsUsed = async (pillId: string) => {
    try {
      const effectiveWineKey = wineKey || "wine_1";
      await fetch("/api/suggestion-pills/used", {
        method: "POST",
        body: JSON.stringify({
          wineKey: effectiveWineKey,
          suggestionId: pillId,
          userId: null,
        }),
        headers: { "Content-Type": "application/json" },
      });
      // Removed refetch() - suggestions stay stable until manual refresh
    } catch (error) {
      console.error("Error marking pill as used:", error);
    }
  };

  // Always show exactly 3 pills
  const visiblePills = useMemo(() => {
    const availablePills = suggestionsData?.suggestions || [];

    if (isLoading || availablePills.length === 0) {
      return defaultSuggestions.slice(0, 3);
    }

    // Only show unused pills - never show used ones
    const unusedPills = availablePills.filter(
      (pill: SuggestionPill) => !usedPills.has(pill.id),
    );

    // Always show exactly 3 unused pills if available
    if (unusedPills.length >= 3) {
      return unusedPills.slice(0, 3);
    }

    // If we have some unused pills but less than 3, show what we have
    if (unusedPills.length > 0) {
      return unusedPills;
    }

    // If all suggestions are used, show default suggestions instead of auto-resetting
    if (unusedPills.length === 0 && availablePills.length > 0) {
      console.log("All suggestions used - showing default suggestions (no auto-reset)");
      return defaultSuggestions.slice(0, 3);
    }

    // Fallback: show unused default suggestions if no API suggestions available
    const unusedDefaults = defaultSuggestions.filter(def => !usedPills.has(def.id));
    return unusedDefaults.slice(0, 3);
  }, [suggestionsData, usedPills, isLoading]);

  return (
    <div
      style={{
        display: "flex",
        flexDirection: "row",
        gap: "12px",
        padding: "0",
        margin: "0",
        overflowX: "auto",
        scrollbarWidth: "none",
        msOverflowStyle: "none",
        WebkitScrollbar: { display: "none" },
      }}
    >
      <style>
        {`
          div::-webkit-scrollbar {
            display: none;
          }
          @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
          }
        `}
      </style>
      {visiblePills.map((pill: SuggestionPill) => {
        const effectiveWineKey = wineKey || "wine_1";
        const suggestionId = pill.prompt.toLowerCase().replace(/[^a-z0-9]+/g, "_");
        const cacheKey = `${effectiveWineKey}_${suggestionId}`;
        const preGenStatus = preGenerationStatus.get(cacheKey);
        const isLoading = loadingPillId === pill.id;
        const showFallback = isLoading && context === "voice-assistant";

        return (
          <Button
            key={`${context}-${pill.id}`}
            variant="secondary"
            disabled={isDisabled || isProcessing}
            onClick={() => handlePillClick(pill)}
            style={{
              ...typography.buttonPlus1,
              minWidth: "fit-content",
              whiteSpace: "nowrap",
              flexShrink: 0,
              borderRadius: "32px",
              padding: "12px 20px",
              transition: "none",
              position: "relative",
              opacity: isLoading ? 0.7 : 1,
              background: preGenStatus === 'ready' && context === "voice-assistant" 
                ? 'linear-gradient(135deg, #2563eb 0%, #1d4ed8 100%)' 
                : undefined,
              color: preGenStatus === 'ready' && context === "voice-assistant" ? '#ffffff' : undefined,
            }}
          >
            {showFallback ? "Loading audio..." : pill.text}
            {isLoading && (
              <div style={{
                position: "absolute",
                right: "8px",
                top: "50%",
                transform: "translateY(-50%)",
                width: "12px",
                height: "12px",
                border: "2px solid #ffffff",
                borderTop: "2px solid transparent",
                borderRadius: "50%",
                animation: "spin 1s linear infinite",
              }} />
            )}
            {preGenStatus === 'ready' && context === "voice-assistant" && !isLoading && (
              <div style={{
                position: "absolute",
                right: "8px",
                top: "50%",
                transform: "translateY(-50%)",
                width: "8px",
                height: "8px",
                background: "#10b981",
                borderRadius: "50%",
                boxShadow: "0 0 4px rgba(16, 185, 129, 0.5)",
              }} />
            )}
          </Button>
        );
      })}
    </div>
  );
}
